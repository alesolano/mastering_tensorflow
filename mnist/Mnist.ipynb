{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 2\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to KEEP units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & biases in dictionaries\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32]), name='Wc1'), \n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64]), name='Wc2'),   \n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024]), name='Wfc'),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]), name='Wo') \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32]), name='bc1'),\n",
    "    'bc2': tf.Variable(tf.random_normal([64]), name='bc2'),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024]), name='bfc'),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]), name='bo')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1, name='conv'):\n",
    "    with tf.name_scope(name):\n",
    "        x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        x = tf.nn.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2, name='max_pool'):\n",
    "    with tf.name_scope(name):\n",
    "        x = tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28x28x1 to 14x14x32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'], name='conv1')\n",
    "    conv1 = maxpool2d(conv1, k=2, name='max_pool1')\n",
    "\n",
    "    # Layer 2 - 14x14x32 to 7x7x64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'], name='conv2')\n",
    "    conv2 = maxpool2d(conv2, k=2, name='max_pool2')\n",
    "\n",
    "    # Fully conected Layer - 7x7x64 to 1024\n",
    "    with tf.name_scope('fc1'):\n",
    "        fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "        fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "        fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    with tf.name_scope('fc2'):\n",
    "        # Output Layer - class prediction - 1024 to 10\n",
    "        out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # keep probability (dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiliazing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saver for variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 52449.0547 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  21 -Loss: 17830.0605 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  41 -Loss: 10975.2891 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  61 -Loss:  9802.1846 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  81 -Loss:  5447.2822 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 101 -Loss:  6139.3857 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 121 -Loss:  4312.1978 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 141 -Loss:  3192.7578 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 161 -Loss:  3069.9678 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 181 -Loss:  3549.9915 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 201 -Loss:  2428.4602 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 221 -Loss:  2738.0864 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 241 -Loss:  3223.9014 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 261 -Loss:  1401.6622 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 281 -Loss:  1987.6003 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 301 -Loss:  2996.6997 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 321 -Loss:  2585.2896 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 341 -Loss:  1660.2131 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 361 -Loss:  2354.2896 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 381 -Loss:  1844.2211 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 401 -Loss:  1811.8611 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 421 -Loss:  2204.2578 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch   1 -Loss:   694.7831 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  21 -Loss:  1250.6064 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch  41 -Loss:  1294.2006 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch  61 -Loss:  1331.3356 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch  81 -Loss:  1241.0347 Validation Accuracy: 0.816406\n",
      "Epoch  2, Batch 101 -Loss:  1280.1382 Validation Accuracy: 0.824219\n",
      "Epoch  2, Batch 121 -Loss:  1218.7195 Validation Accuracy: 0.820312\n",
      "Epoch  2, Batch 141 -Loss:  1383.2189 Validation Accuracy: 0.835938\n",
      "Epoch  2, Batch 161 -Loss:  1184.8389 Validation Accuracy: 0.820312\n",
      "Epoch  2, Batch 181 -Loss:  2398.1382 Validation Accuracy: 0.832031\n",
      "Epoch  2, Batch 201 -Loss:  1290.1885 Validation Accuracy: 0.824219\n",
      "Epoch  2, Batch 221 -Loss:  1491.4205 Validation Accuracy: 0.832031\n",
      "Epoch  2, Batch 241 -Loss:  1142.2065 Validation Accuracy: 0.832031\n",
      "Epoch  2, Batch 261 -Loss:  1225.5406 Validation Accuracy: 0.828125\n",
      "Epoch  2, Batch 281 -Loss:  1651.9521 Validation Accuracy: 0.839844\n",
      "Epoch  2, Batch 301 -Loss:  1157.6609 Validation Accuracy: 0.843750\n",
      "Epoch  2, Batch 321 -Loss:  1284.6847 Validation Accuracy: 0.847656\n",
      "Epoch  2, Batch 341 -Loss:  1237.9509 Validation Accuracy: 0.843750\n",
      "Epoch  2, Batch 361 -Loss:   777.3955 Validation Accuracy: 0.847656\n",
      "Epoch  2, Batch 381 -Loss:  1146.8723 Validation Accuracy: 0.859375\n",
      "Epoch  2, Batch 401 -Loss:  1162.2581 Validation Accuracy: 0.851562\n",
      "Epoch  2, Batch 421 -Loss:   584.2782 Validation Accuracy: 0.851562\n",
      "Testing Accuracy: 0.828125\n",
      "Model saved in file: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            if batch%20 == 0:\n",
    "                print('Epoch {:>2}, Batch {:3} -'\n",
    "                    'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                        epoch + 1, \n",
    "                        batch + 1,\n",
    "                        loss,\n",
    "                        valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))\n",
    "\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"./tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
